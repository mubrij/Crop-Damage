{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-01 10:48:32.073189: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-01 10:48:32.074472: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-01 10:48:32.092870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-01 10:48:32.092888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-01 10:48:32.093438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-01 10:48:32.096701: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-01 10:48:32.579960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from timm import create_model\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fastai.callback.mixup import *\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchmetrics.classification import Accuracy\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "SEED = 2023\n",
    "N_FOLDS = 5\n",
    "BATCH_SIZE = 20\n",
    "IMGSZ = 384\n",
    "EPOCHS = 10\n",
    "INIT_LR = 2e-4\n",
    "NUM_WORKER = 8\n",
    "PATIENCE = 3\n",
    "MODEL_BASE = 'convnext_large_in22k' # vit_small_patch16_224, convnext_base_fb_in22k\n",
    "\n",
    "\n",
    "Train = 'Train (27).csv'\n",
    "Test = 'Test (30).csv'\n",
    "\n",
    "set_seed(SEED, reproducible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_train_data(data, kfold, image_dir):\n",
    "    \"\"\"\n",
    "    Helper function to get the data ready\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    df['image_id'] = df['filename'].apply(lambda x: x.split('.')[0])\n",
    "    df = df.drop_duplicates(subset='image_id', keep='first')\n",
    "\n",
    "    df['target'] = df['damage']\n",
    "\n",
    "    df['fold'] = -1\n",
    "    for i, (train_idx, val_idx) in enumerate(kfold.split(df, df['target'])):\n",
    "        df.loc[val_idx, 'fold'] = i\n",
    "\n",
    "    print(df.groupby(['fold', 'target']).size())\n",
    "\n",
    "    df['path'] = df['filename'].apply(lambda x: f'{image_dir}/{x}')\n",
    "    df['fold'] = df['fold'].astype('int')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(predictions, targets, alpha=0.25, gamma=2):\n",
    "    predictions = predictions.sigmoid()\n",
    "    \n",
    "    # Convert targets to one-hot encoding\n",
    "    targets_one_hot = F.one_hot(targets, num_classes=predictions.size(1)).float()\n",
    "\n",
    "    focal_weight = alpha * targets_one_hot * (1 - predictions) ** gamma + (1 - alpha) * (1 - targets_one_hot) * predictions ** gamma\n",
    "    loss = F.binary_cross_entropy_with_logits(predictions, targets_one_hot, reduction='none')\n",
    "    \n",
    "    return (focal_weight * loss).mean()\n",
    "\n",
    "\n",
    "def train_model(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    for fold in range(N_FOLDS):\n",
    "        df['is_valid'] = (df['fold'] == fold)\n",
    "        print(f'Training fold: {fold}')\n",
    "\n",
    "        undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=SEED)\n",
    "        _, sample_indices = undersampler.fit_resample(df[df['fold'] != fold][['path']], df[df['fold'] != fold]['target'])\n",
    "        df.loc[df.index.isin(sample_indices), 'undersampled'] = True\n",
    "        df['undersampled'] = df['undersampled'].fillna(False).astype(bool)\n",
    "\n",
    "        oversampler = RandomOverSampler(sampling_strategy='auto', random_state=SEED)\n",
    "        _, sample_indices = oversampler.fit_resample(df[df['fold'] == fold][['path']], df[df['fold'] == fold]['target'])\n",
    "        df.loc[df.index.isin(sample_indices), 'oversampled'] = True\n",
    "        df['oversampled'] = df['oversampled'].fillna(False).astype(bool)\n",
    "\n",
    "        pca_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('pca', PCA(n_components=10))\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('pca', pca_transformer, ['path'])\n",
    "            ])\n",
    "        damage = pd.read_csv(Train).damage.unique()\n",
    "        dblock = DataBlock(blocks=(ImageBlock, CategoryBlock(vocab=damage)),\n",
    "                   get_x=ColReader('path'),\n",
    "                   get_y=ColReader('target'),\n",
    "                   splitter=ColSplitter('is_valid'),\n",
    "                   item_tfms=Resize(IMGSZ),\n",
    "                   batch_tfms=[*aug_transforms(mult=2),\n",
    "                               Rotate(max_deg=20),\n",
    "                               Flip(),\n",
    "                               Brightness(max_lighting=0.6),\n",
    "                               Contrast(max_lighting=0.6),\n",
    "                               Zoom(max_zoom=1.1),\n",
    "                               Warp(),\n",
    "                               Dihedral(),\n",
    "                               RandomErasing(p=0.2),\n",
    "                               CropPad(size=128),\n",
    "                               RandomResizedCrop(128),\n",
    "                           ])\n",
    "        dls = dblock.dataloaders(df,\n",
    "                                bs=BATCH_SIZE,\n",
    "                                num_workers=NUM_WORKER,\n",
    "                                oversample_col='oversampled',\n",
    "                                undersample_col='undersampled',\n",
    "                                preproc_fn=preprocessor)\n",
    "\n",
    "        model = MODEL_BASE\n",
    "        learn = vision_learner(dls, model, loss_func=focal_loss, metrics=accuracy).to_fp16()\n",
    "\n",
    "        learn.fine_tune(10, base_lr=INIT_LR)\n",
    "\n",
    "        learn = learn.to_fp32()\n",
    "        learn.save(f'{MODEL_BASE}_fold{fold}', with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(Train)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  target\n",
      "0     DR         903\n",
      "      G         2325\n",
      "      ND          54\n",
      "      WD        1848\n",
      "      other       84\n",
      "1     DR         904\n",
      "      G         2324\n",
      "      ND          54\n",
      "      WD        1848\n",
      "      other       84\n",
      "2     DR         903\n",
      "      G         2324\n",
      "      ND          55\n",
      "      WD        1848\n",
      "      other       84\n",
      "3     DR         903\n",
      "      G         2325\n",
      "      ND          55\n",
      "      WD        1847\n",
      "      other       83\n",
      "4     DR         903\n",
      "      G         2325\n",
      "      ND          54\n",
      "      WD        1847\n",
      "      other       84\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_train_data(train, skf, 'images')\n",
    "#train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3811965/797184235.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'True' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df.index.isin(sample_indices), 'undersampled'] = True\n",
      "/tmp/ipykernel_3811965/797184235.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'True' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df.index.isin(sample_indices), 'oversampled'] = True\n",
      "/home/unicconaiadmin/.local/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_large_in22k to current convnext_large.fb_in22k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 23.69 GiB total capacity; 721.24 MiB already allocated; 2.94 MiB free; 788.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m MODEL_BASE\n\u001b[1;32m     59\u001b[0m learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, model, loss_func\u001b[38;5;241m=\u001b[39mfocal_loss, metrics\u001b[38;5;241m=\u001b[39maccuracy)\u001b[38;5;241m.\u001b[39mto_fp16()\n\u001b[0;32m---> 61\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_BASE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_fold\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_df)\n\u001b[1;32m     64\u001b[0m test_dl \u001b[38;5;241m=\u001b[39m dls\u001b[38;5;241m.\u001b[39mtest_dl(test_df)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fastai/learner.py:420\u001b[0m, in \u001b[0;36mload\u001b[0;34m(self, file, device, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m file \u001b[38;5;241m=\u001b[39m join_path_file(file, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir, ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    419\u001b[0m distrib_barrier()\n\u001b[0;32m--> 420\u001b[0m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fastai/learner.py:51\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(file, model, opt, with_opt, device, strict, **torch_load_kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m): device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, device)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 51\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtorch_load_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m hasopt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(state)\u001b[38;5;241m==\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     53\u001b[0m model_state \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m hasopt \u001b[38;5;28;01melse\u001b[39;00m state\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1086\u001b[0m, in \u001b[0;36m_get_restore_location.<locals>.restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_location\u001b[39m(storage, location):\n\u001b[0;32m-> 1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_restore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:187\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:81\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_type(indices, values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 23.69 GiB total capacity; 721.24 MiB already allocated; 2.94 MiB free; 788.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "TTA = 5\n",
    "df = train_data\n",
    "os.makedirs('submission', exist_ok=True)\n",
    "\n",
    "test_df = pd.read_csv(Test)\n",
    "test_df['path'] = test_df['filename'].map(lambda x: f'images/{x}')\n",
    "\n",
    "ensemble = []\n",
    "for fold in range(N_FOLDS):\n",
    "    df['is_valid'] = (df['fold'] == fold)\n",
    "    print(f'Training fold: {fold}')\n",
    "\n",
    "    undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=SEED)\n",
    "    _, sample_indices = undersampler.fit_resample(df[df['fold'] != fold][['path']], df[df['fold'] != fold]['target'])\n",
    "    df.loc[df.index.isin(sample_indices), 'undersampled'] = True\n",
    "    df['undersampled'] = df['undersampled'].fillna(False).astype(bool)\n",
    "\n",
    "    oversampler = RandomOverSampler(sampling_strategy='auto', random_state=SEED)\n",
    "    _, sample_indices = oversampler.fit_resample(df[df['fold'] == fold][['path']], df[df['fold'] == fold]['target'])\n",
    "    df.loc[df.index.isin(sample_indices), 'oversampled'] = True\n",
    "    df['oversampled'] = df['oversampled'].fillna(False).astype(bool)\n",
    "\n",
    "    pca_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('pca', PCA(n_components=10))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('pca', pca_transformer, ['path'])\n",
    "        ])\n",
    "    damage = pd.read_csv(Train).damage.unique()\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock(vocab=damage)),\n",
    "                get_x=ColReader('path'),\n",
    "                get_y=ColReader('target'),\n",
    "                splitter=ColSplitter('is_valid'),\n",
    "                item_tfms=Resize(IMGSZ),\n",
    "                batch_tfms=[*aug_transforms(mult=2),\n",
    "                            Rotate(max_deg=20),\n",
    "                            Flip(),\n",
    "                            Brightness(max_lighting=0.6),\n",
    "                            Contrast(max_lighting=0.6),\n",
    "                            Zoom(max_zoom=1.1),\n",
    "                            Warp(),\n",
    "                            Dihedral(),\n",
    "                            RandomErasing(p=0.2),\n",
    "                            CropPad(size=128),\n",
    "                            RandomResizedCrop(128),\n",
    "                        ])\n",
    "    dls = dblock.dataloaders(df,\n",
    "                            bs=BATCH_SIZE,\n",
    "                            num_workers=NUM_WORKER,\n",
    "                            oversample_col='oversampled',\n",
    "                            undersample_col='undersampled',\n",
    "                            preproc_fn=preprocessor)\n",
    "\n",
    "    model = MODEL_BASE\n",
    "    learn = vision_learner(dls, model, loss_func=focal_loss, metrics=accuracy).to_fp16()\n",
    "\n",
    "    learn = learn.load(f'{MODEL_BASE}_fold{fold}')\n",
    "    test_df['target'] = [1]*len(test_df)\n",
    "\n",
    "    test_dl = dls.test_dl(test_df)\n",
    "    preds, _ = learn.tta(dl=test_dl, n=TTA, beta=0)\n",
    "    ensemble.append(preds.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.join(pd.DataFrame(np.mean(ensemble, axis=0), columns=dls.vocab))\n",
    "\n",
    "sample_submission_df = pd.read_csv(\"Sample Cnn.csv\")\n",
    "sample_submission_df = sample_submission_df['ID']\n",
    "sample_submission_df = pd.merge(sample_submission_df, test_df, on='ID')\n",
    "sample_submission_df = sample_submission_df[['ID']+dls.vocab]\n",
    "sample_submission_df.to_csv(f\"submission/{MODEL_BASE}_tta_{TTA}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
